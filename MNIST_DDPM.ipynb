{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "# DDPM+DDIM with MNIST\n",
    "****"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## General Presets"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "outputs": [],
   "source": [
    "\"\"\" Import packages \"\"\"\n",
    "import gc\n",
    "import math\n",
    "# Numerical Operations\n",
    "import random\n",
    "import numpy as np\n",
    "# Pytorch\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.cuda.amp import autocast, GradScaler\n",
    "scaler = GradScaler()\n",
    "import torchvision.transforms as transforms\n",
    "from torch.utils.data import DataLoader, random_split\n",
    "from torchvision.utils import save_image\n",
    "from torchvision import datasets\n",
    "# my_utilities\n",
    "import my_utilities as my_utils"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2024-02-24T18:09:58.845109Z",
     "end_time": "2024-02-24T18:09:58.847115Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [],
   "source": [
    "\"\"\" For Auto-reload Modules\"\"\"\n",
    "\n",
    "%reload_ext autoreload\n",
    "%autoreload 2"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2024-02-16T12:27:18.687581Z",
     "end_time": "2024-02-16T12:27:18.687581Z"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Configurations"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [],
   "source": [
    "\"\"\" Set paths & device \"\"\"\n",
    "\n",
    "data_dir, checkpoints_dir, results_dir = 'data/', 'checkpoints/', 'results/'\n",
    "device = my_utils.register_device()\n",
    "\n",
    "\"\"\" Set model options \"\"\"\n",
    "\n",
    "hp = {\n",
    "\t# ============= data ==============\n",
    "\t'batch_size': 64,\n",
    "    # ============= model ==============\n",
    "\t'input_size': 32,\n",
    "\t'in_chan': 1,\n",
    "\t'out_chan': 1,\n",
    "\t't_chan': 256,\n",
    "\t'fst_filters': 64,\n",
    "\t'lst_chan': 1024,\n",
    "\t'groups': 32,\n",
    "\t'drop_rate': 0.1,\n",
    "\t'train_T': 100,\n",
    "\t'sampling_T': 25,\n",
    "    # ============= training ==============\n",
    "\t'init_lr': 2e-4,\n",
    "\t'epoch_num': 5,\n",
    "\t# ============= testing =============\n",
    "\t'samples_num': 5\n",
    "}"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2024-02-16T12:27:18.688581Z",
     "end_time": "2024-02-16T12:27:18.688581Z"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Data Preparation"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [],
   "source": [
    "\"\"\" Create datasets \"\"\"\n",
    "\n",
    "raw_train_set = datasets.MNIST('./data', train=True,\n",
    "\t\t\t\t\t\t\t   transform=\n",
    "\t\t\t\t\t\t\t   transforms.Compose([\n",
    "\t\t\t\t\t\t\t\t   transforms.Resize((32, 32)),\n",
    "\t\t\t\t\t\t\t\t   transforms.ToTensor()]),\n",
    "\t\t\t\t\t\t\t   download=False)\n",
    "\n",
    "train_len = int(len(raw_train_set) * 0.8)\n",
    "val_len = int(len(raw_train_set) * 0.2)\n",
    "train_set, val_set = random_split(raw_train_set, [train_len, val_len])\n",
    "\n",
    "train_batches = DataLoader(train_set, shuffle=True, batch_size=hp['batch_size'], pin_memory=True)\n",
    "val_batches = DataLoader(train_set, shuffle=False, batch_size=hp['batch_size'] * 2, pin_memory=True)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2024-02-16T12:27:18.790475Z",
     "end_time": "2024-02-16T12:27:18.790475Z"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Build Model"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [],
   "source": [
    "\"\"\" Define weight initialization \"\"\"\n",
    "\n",
    "\n",
    "def weights_init(m):\n",
    "\tif isinstance(m, nn.Module):\n",
    "\t\tfor name, param in m.named_parameters():\n",
    "\t\t\tif param.requires_grad:\n",
    "\t\t\t\tname = name.replace('.', '_')\n",
    "\t\t\t\tm.register_buffer(f\"ema_{name}\", param.data.clone())\n",
    "\t\t\t\tif not hasattr(m, 'ema_decay'): m.ema_decay = 0.9999\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2024-02-16T12:27:18.836561Z",
     "end_time": "2024-02-16T12:27:18.836561Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "outputs": [],
   "source": [
    "\"\"\" Define ResBlock & AttnBlock \"\"\"\n",
    "\n",
    "\n",
    "class ResBlock(nn.Module):\n",
    "\tdef __init__(self, in_chan, out_chan, t_chan, groups=32, drop_rate=0.1):\n",
    "\t\t\"\"\"\n",
    "\t\tResidual block\n",
    "\t\t:param in_chan: number of input channels\n",
    "\t\t:param out_chan: number of output channels\n",
    "\t\t:param t_chan: number of time-tensor's channels\n",
    "\t\t\"\"\"\n",
    "\t\tsuper().__init__()\n",
    "\n",
    "\t\tself.block = nn.ModuleDict()\n",
    "\t\tself.in_chan, self.out_chan, self.t_chan = in_chan, out_chan, t_chan\n",
    "\n",
    "\t\tself.F1, self.S1, self.P1 = 3, 1, 1\n",
    "\t\tself.F2, self.S2, self.P2 = 1, 1, 0\n",
    "\t\tself.groups = groups\n",
    "\t\tself.drop_rate = drop_rate\n",
    "\n",
    "\t\tself.set_block()\n",
    "\n",
    "\t\t# self.apply(weights_init)\n",
    "\n",
    "\tdef forward(self, X, t):\n",
    "\t\tin_X = X\n",
    "\t\tX = self.block['conv1'](X)\n",
    "\t\tt = self.block['adjust_t'](t)[:, :, None, None]  # resize to same dims as X\n",
    "\t\ty = self.block['conv2'](X + t)  # embed\n",
    "\t\ty += self.block['adjust_x'](in_X)  # shortcut\n",
    "\t\treturn y\n",
    "\n",
    "\tdef set_block(self):\n",
    "\t\t\"\"\"\"\"\"\n",
    "\t\t\"\"\" conv input X \"\"\"\n",
    "\t\tself.block['conv1'] = nn.Sequential(\n",
    "\t\t\tnn.GroupNorm(self.groups, self.in_chan),\n",
    "\t\t\tnn.SiLU(),\n",
    "\t\t\tnn.Conv2d(self.in_chan, self.out_chan, self.F1, self.S1, self.P1))\n",
    "\n",
    "\t\t\"\"\" adjust t \"\"\"\n",
    "\t\tself.block['adjust_t'] = nn.Sequential(\n",
    "\t\t\tnn.SiLU(),\n",
    "\t\t\tnn.Linear(self.t_chan, self.out_chan))\n",
    "\n",
    "\t\t\"\"\" conv (X + t) \"\"\"\n",
    "\t\tself.block['conv2'] = nn.Sequential(\n",
    "\t\t\tnn.GroupNorm(self.groups, self.out_chan),\n",
    "\t\t\tnn.SiLU(),\n",
    "\t\t\tnn.Dropout(self.drop_rate),\n",
    "\t\t\tnn.Conv2d(self.out_chan, self.out_chan, self.F1, self.S1, self.P1))\n",
    "\n",
    "\t\t\"\"\" prepare X for shortcut \"\"\"\n",
    "\t\tself.block['adjust_x'] = nn.Conv2d(self.in_chan, self.out_chan, self.F2, self.S2, self.P2) \\\n",
    "\t\t\tif self.in_chan != self.out_chan else nn.Identity()\n",
    "\n",
    "\n",
    "class AttnBlock(nn.Module):\n",
    "\tdef __init__(self, chan, heads=1, d_k=None, groups=32):\n",
    "\t\t\"\"\"\n",
    "\t\tSelf-attention Block\n",
    "\t\t:param chan: number of input channels\n",
    "\t\t:param heads: number of attention heads\n",
    "\t\t:param d_k: number of each head's dims\n",
    "\t\t\"\"\"\n",
    "\t\tsuper().__init__()\n",
    "\n",
    "\t\tself.chan, self.heads = chan, heads\n",
    "\t\tself.d_k = self.chan if d_k is None else d_k\n",
    "\t\tself.groups = groups\n",
    "\n",
    "\t\tself.prj = nn.Linear(self.chan, self.heads * self.d_k * 3)\n",
    "\t\tself.softmax = nn.Softmax(dim=2)\n",
    "\t\tself.mlp = nn.Linear(self.heads * self.d_k, self.chan)\n",
    "\n",
    "\t\t# self.apply(weights_init)\n",
    "\n",
    "\tdef forward(self, X):\n",
    "\t\t# get q, k, v\n",
    "\t\tb, ch, h, w = X.shape\n",
    "\t\tX = X.view(b, ch, -1).permute(0, 2, 1)  # (b, ch, h, w) => (b, h*w, ch) = (b, seq_len, embed_ch)\n",
    "\t\tq, k, v = torch.chunk(self.prj(X).view(b, -1, self.heads, self.d_k * 3), 3, dim=-1)\n",
    "\t\t# self-attention\n",
    "\t\tattn = self.softmax(torch.einsum('bihd,bjhd->bijh', q, k) * (self.d_k ** -0.5))\n",
    "\t\tscores = torch.einsum('bijh,bjhd->bihd', attn, v).view(b, -1, self.heads * self.d_k)\n",
    "\t\ty = self.mlp(scores)\n",
    "\t\t# shortcut\n",
    "\t\ty = (y + X).permute(0, 2, 1).view(b, ch, h, w)\n",
    "\t\treturn y"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2024-02-16T12:27:18.853142Z",
     "end_time": "2024-02-16T12:27:18.853142Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "outputs": [],
   "source": [
    "\"\"\" Define Unet architecture \"\"\"\n",
    "\n",
    "\n",
    "class Unet(nn.Module):\n",
    "\tdef __init__(self, img_size=32, in_chan=3, out_chan=3, t_chan=256, fst_filters=64, lst_chan=1024, groups=32,\n",
    "\t\t\t\t drop_rate=0.1, verbose=False):\n",
    "\t\t\"\"\"\n",
    "\t\tComplete Architecture\n",
    "\t\t:param img_size: width (or height) of input img.\n",
    "\t\t:param in_chan: number of input channels\n",
    "\t\t:param out_chan: number of output channels\n",
    "\t\t:param t_chan:\n",
    "\t\t:param fst_filters: number of filters in the first conv.\n",
    "\t\t:param lst_chan: number of channels of the encoder's output\n",
    "\t\t:param groups: number of groups in GroupNorm\n",
    "\t\t:param drop_rate: dropout's rate\n",
    "\t\t:param verbose: whether to print messages in the process\n",
    "\t\t\"\"\"\n",
    "\t\tsuper().__init__()\n",
    "\t\tself.encoder = nn.ModuleList()\n",
    "\t\tself.bridge = nn.ModuleDict()\n",
    "\t\tself.decoder = nn.ModuleList()\n",
    "\n",
    "\t\tself.N = img_size\n",
    "\t\tself.in_chan, self.out_chan, self.t_chan = in_chan, out_chan, t_chan\n",
    "\n",
    "\t\tself.fst_filter, self.lst_chan = fst_filters, lst_chan\n",
    "\t\tself.norm, self.groups = nn.GroupNorm, groups\n",
    "\t\tself.drop_rate = drop_rate\n",
    "\n",
    "\t\tself.F1, self.S1, self.P1 = 3, 1, 1\n",
    "\t\tself.F2, self.S2, self.P2 = 4, 2, 1\n",
    "\n",
    "\t\tself.ver = verbose\n",
    "\n",
    "\t\tself.layers_num = 4\n",
    "\t\t# except the first & the last, each layer has conv. & 2 blocks: Res & Self-Attention\n",
    "\t\tself.en_results = []  # all 3 parts of results are to be appended\n",
    "\n",
    "\t\tself.pile_encoder()\n",
    "\t\tif self.ver: print('-----------------------------------------------------')\n",
    "\t\tself.set_bridge()\n",
    "\t\tif self.ver: print('-----------------------------------------------------')\n",
    "\t\tself.pile_decoder()\n",
    "\t\tif self.ver: print('=====================================================\\n')\n",
    "\n",
    "\t\tself.apply(weights_init)\n",
    "\n",
    "\tdef forward(self, X, t):\n",
    "\t\tt = self.t_vector2tensor(t)\n",
    "\t\tlatent = self.en_forward(X, t)\n",
    "\t\tlatent = self.bridge_forward(latent, t)\n",
    "\t\ty = self.de_forward(latent, t)\n",
    "\n",
    "\t\tif self.ver: print(\"\\nforwarding done.\\n\"\n",
    "\t\t\t\t\t\t   \"=====================================================\\n\")\n",
    "\t\treturn y\n",
    "\n",
    "\tdef t_vector2tensor(self, t: torch.Tensor):\n",
    "\t\tif self.ver: print(\"init -> t's dims = \" + str(t.shape))\n",
    "\t\thalf_dim = self.t_chan // 8\n",
    "\t\temb = math.log(10_000) / (half_dim - 1)\n",
    "\t\temb = torch.exp(torch.arange(half_dim, device=t.device) * -emb)\n",
    "\t\tt = t.unsqueeze(1) * emb.unsqueeze(0)\n",
    "\t\tif self.ver: print(\"encoded -> t's dims = \" + str(t.shape))\n",
    "\t\tt = torch.cat((t.sin(), t.cos()), dim=1)\n",
    "\t\tif self.ver: print(\"cat -> t's dims = \" + str(t.shape))\n",
    "\t\tt = nn.Linear(self.t_chan // 4, self.t_chan).to(t.device)(t)\n",
    "\t\tif self.ver: print(\"linear1 -> t's dims = \" + str(t.shape))\n",
    "\t\tt = nn.SiLU().to(t.device)(t)\n",
    "\t\tif self.ver: print(\"Swish -> t's dims = \" + str(t.shape))\n",
    "\t\tt = nn.Linear(self.t_chan, self.t_chan).to(t.device)(t)\n",
    "\t\tif self.ver: print(\"linear2 -> t's dims = \" + str(t.shape))\n",
    "\n",
    "\t\tif self.ver: print(\"t_vector2tensor done.\")\n",
    "\t\treturn t\n",
    "\n",
    "\tdef pile_encoder(self):  # downwards\n",
    "\t\tfor i in range(self.layers_num):\n",
    "\t\t\t\"\"\" CONV \"\"\"\n",
    "\t\t\tif i == 0:\n",
    "\t\t\t\tin_chan = self.in_chan\n",
    "\t\t\t\tout_chan = self.fst_filter\n",
    "\t\t\t\tF, S, P = self.F1, self.S1, self.P1\n",
    "\t\t\telse:\n",
    "\t\t\t\tin_chan = self.fst_filter * (2 ** (i - 1))\n",
    "\t\t\t\tout_chan = in_chan\n",
    "\t\t\t\tF, S, P = self.F2, self.S2, self.P2\n",
    "\t\t\tconv = nn.Conv2d(in_chan, out_chan, F, S, P)\n",
    "\t\t\tself.encoder.append(conv)\n",
    "\t\t\tif self.ver: print(\"(conv)\")\n",
    "\n",
    "\t\t\t\"\"\" RES + ATTN block \"\"\"\n",
    "\t\t\tblock = nn.ModuleDict()\n",
    "\t\t\tif i == 0:\n",
    "\t\t\t\tin_chan = out_chan = self.fst_filter\n",
    "\t\t\telif i == self.layers_num - 1:\n",
    "\t\t\t\tin_chan, out_chan = self.fst_filter * (2 ** (i - 1)), self.lst_chan\n",
    "\t\t\telse:\n",
    "\t\t\t\tin_chan = self.fst_filter * (2 ** (i - 1))\n",
    "\t\t\t\tout_chan = in_chan * 2\n",
    "\t\t\tblock['res'] = ResBlock(in_chan, out_chan, self.t_chan)\n",
    "\t\t\tblock['attn'] = AttnBlock(out_chan)\n",
    "\t\t\tself.encoder.append(block)\n",
    "\t\t\tif self.ver: print(\"(res -> attn)\")\n",
    "\n",
    "\t\t\t\"\"\" RES + ATTN block \"\"\"\n",
    "\t\t\tblock = nn.ModuleDict()\n",
    "\t\t\tif i == 0:\n",
    "\t\t\t\tin_chan = out_chan = self.fst_filter\n",
    "\t\t\telif i == self.layers_num - 1:\n",
    "\t\t\t\tin_chan = out_chan = self.lst_chan\n",
    "\t\t\telse:\n",
    "\t\t\t\tin_chan = out_chan = self.fst_filter * (2 ** i)\n",
    "\t\t\tblock['res'] = ResBlock(in_chan, out_chan, self.t_chan)\n",
    "\t\t\tblock['attn'] = AttnBlock(out_chan)\n",
    "\t\t\tself.encoder.append(block)\n",
    "\t\t\tif self.ver: print(\"(res -> attn)\")\n",
    "\n",
    "\t\t\tif self.ver: print(\"piling en-layer \" + str(i + 1) + \" done.\")\n",
    "\n",
    "\tdef set_bridge(self):\n",
    "\t\t\"\"\"\"\"\"\n",
    "\t\t\"\"\" RES + ATTN + RES block \"\"\"\n",
    "\t\tin_chan = out_chan = self.lst_chan\n",
    "\t\tself.bridge['res1'] = ResBlock(in_chan, out_chan, self.t_chan)\n",
    "\t\tself.bridge['attn'] = AttnBlock(out_chan)\n",
    "\t\tself.bridge['res2'] = ResBlock(in_chan, out_chan, self.t_chan)\n",
    "\t\tif self.ver: print(\"(res -> attn -> res)\")\n",
    "\t\tif self.ver: print(\"setting bridge done.\")\n",
    "\n",
    "\tdef pile_decoder(self):  # upwards\n",
    "\t\tfor i in range(self.layers_num):\n",
    "\t\t\t\"\"\" RES + ATTN block \"\"\"\n",
    "\t\t\tblock = nn.ModuleDict()\n",
    "\t\t\tif i == 0:\n",
    "\t\t\t\tin_chan, out_chan = self.lst_chan * 2, self.lst_chan\n",
    "\t\t\telse:\n",
    "\t\t\t\tin_chan = self.lst_chan // (2 ** i)\n",
    "\t\t\t\tout_chan = in_chan // 2\n",
    "\t\t\tblock['res'] = ResBlock(in_chan, out_chan, self.t_chan)\n",
    "\t\t\tblock['attn'] = AttnBlock(out_chan)\n",
    "\t\t\tself.decoder.append(block)\n",
    "\t\t\tif self.ver: print(\"(res -> attn)\")\n",
    "\n",
    "\t\t\t\"\"\" RES + ATTN block \"\"\"\n",
    "\t\t\tblock = nn.ModuleDict()\n",
    "\t\t\tif i == 0:\n",
    "\t\t\t\tin_chan, out_chan = self.lst_chan * 2, self.lst_chan\n",
    "\t\t\telse:\n",
    "\t\t\t\tin_chan = self.lst_chan // (2 ** i)\n",
    "\t\t\t\tout_chan = in_chan // 2\n",
    "\t\t\tblock['res'] = ResBlock(in_chan, out_chan, self.t_chan)\n",
    "\t\t\tblock['attn'] = AttnBlock(out_chan)\n",
    "\t\t\tself.decoder.append(block)\n",
    "\t\t\tif self.ver: print(\"(res -> attn)\")\n",
    "\n",
    "\t\t\t\"\"\" RES + ATTN block \"\"\"\n",
    "\t\t\tblock = nn.ModuleDict()\n",
    "\t\t\tif i == 0:\n",
    "\t\t\t\tcat_chan = self.fst_filter * (2 ** (self.layers_num - 2))\n",
    "\t\t\t\tin_chan, out_chan = self.lst_chan + cat_chan, cat_chan\n",
    "\t\t\telif i == self.layers_num - 1:\n",
    "\t\t\t\tcat_chan = self.fst_filter\n",
    "\t\t\t\tin_chan, out_chan = cat_chan + cat_chan, cat_chan\n",
    "\t\t\telse:\n",
    "\t\t\t\tcat_chan = self.lst_chan // (2 ** (i + 2))\n",
    "\t\t\t\tin_chan, out_chan = cat_chan * 2 + cat_chan, cat_chan\n",
    "\t\t\tblock['res'] = ResBlock(in_chan, out_chan, self.t_chan)\n",
    "\t\t\tblock['attn'] = AttnBlock(out_chan)\n",
    "\t\t\tself.decoder.append(block)\n",
    "\t\t\tif self.ver: print(\"(res -> attn)\")\n",
    "\n",
    "\t\t\t\"\"\" CONV^T \"\"\"\n",
    "\t\t\tif i == self.layers_num - 1:\n",
    "\t\t\t\tin_chan = self.fst_filter\n",
    "\t\t\t\tout_chan = self.out_chan\n",
    "\t\t\t\tF, S, P = self.F1, self.S1, self.P1\n",
    "\t\t\telse:\n",
    "\t\t\t\tin_chan = self.fst_filter * (2 ** (self.layers_num - i - 2))\n",
    "\t\t\t\tout_chan = in_chan\n",
    "\t\t\t\tF, S, P = self.F2, self.S2, self.P2\n",
    "\t\t\tconvT = nn.ConvTranspose2d(in_chan, out_chan, F, S, P)\n",
    "\t\t\tself.decoder.append(convT)\n",
    "\t\t\tif self.ver: print(\"(convT)\")\n",
    "\n",
    "\t\t\tif self.ver: print(\"piling de-layer \" + str(i + 1) + \" done.\")\n",
    "\n",
    "\tdef en_forward(self, X, t):\n",
    "\t\tif self.ver: print('=====================================================')\n",
    "\t\tfor i, layer in enumerate(self.encoder, start=1):\n",
    "\t\t\tif not isinstance(layer, nn.ModuleDict):\n",
    "\t\t\t\tself.en_results += [layer(X)]\n",
    "\t\t\t\tif self.ver: print(\"conv...\")\n",
    "\t\t\telse:\n",
    "\t\t\t\tself.en_results += [layer['attn'](layer['res'](X, t))]\n",
    "\t\t\t\tif self.ver: print(\"res... attn...\")\n",
    "\t\t\tX = self.en_results[-1]\n",
    "\t\t\tif self.ver: print(\"X's size = \"+str(X.shape))\n",
    "\t\t\tif self.ver: print(\"forward of en-sublayer \" + str(i) + \" done.\")\n",
    "\t\t\tif self.ver: print('--------------------------------------')\n",
    "\n",
    "\t\tif self.ver: print(\"en-forward done.\")\n",
    "\t\treturn X\n",
    "\n",
    "\tdef bridge_forward(self, X, t):\n",
    "\t\tif self.ver: print('=====================================================')\n",
    "\t\tX = self.bridge['res2'](self.bridge['attn'](self.bridge['res1'](X, t)), t)\n",
    "\t\tif self.ver: print(\"res... attn... res...\")\n",
    "\t\tif self.ver: print(\"X's size = \"+str(X.shape))\n",
    "\t\tif self.ver: print(\"bridge-forward done.\")\n",
    "\t\treturn X\n",
    "\n",
    "\tdef de_forward(self, X, t):  # X is result of bridge\n",
    "\t\tif self.ver: print('=====================================================')\n",
    "\t\tfor i, layer in enumerate(self.decoder, start=1):\n",
    "\t\t\tif not isinstance(layer, nn.ModuleDict):\n",
    "\t\t\t\tX = layer(X)\n",
    "\t\t\t\tif self.ver: print(\"convT...\")\n",
    "\t\t\telse:\n",
    "\t\t\t\tcat_X = torch.concat((X, self.en_results.pop()), dim=1)\n",
    "\t\t\t\tX = layer['attn'](layer['res'](cat_X, t))\n",
    "\t\t\t\tif self.ver: print(\"res... attn...\")\n",
    "\t\t\tif self.ver: print(\"X's size = \"+str(X.shape))\n",
    "\t\t\tif self.ver: print(\"forward of de-sublayer \" + str(i) + \" done.\")\n",
    "\t\t\tif self.ver: print('--------------------------------------')\n",
    "\n",
    "\t\tif self.ver: print(\"de-forward done.\")\n",
    "\t\treturn X\n",
    "\n",
    "\n",
    "# \"\"\" Create Unet instance \"\"\"\n",
    "# model = Unet(\n",
    "# \timg_size=hp['input_size'],\n",
    "# \tin_chan=hp['in_chan'],\n",
    "# \tout_chan=hp['out_chan'],\n",
    "# \tt_chan=hp['t_chan'],\n",
    "# \tfst_filters=hp['fst_filters'],\n",
    "# \tlst_chan=hp['lst_chan'], verbose=True\n",
    "# ).to(device)\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2024-02-16T12:27:18.975174Z",
     "end_time": "2024-02-16T12:27:18.975174Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "outputs": [],
   "source": [
    "# \"\"\" Test Forwarding \"\"\"\n",
    "# batch = next(iter(train_batches))[0].to(device)\n",
    "# t = my_utils.get_t(hp['batch_size'], 100).to(device)\n",
    "# print(batch.shape)\n",
    "# with torch.no_grad(): y = model.forward(batch,t)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2024-02-16T12:27:18.975174Z",
     "end_time": "2024-02-16T12:27:18.975174Z"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Train Model"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "outputs": [],
   "source": [
    "\"\"\" Define EMA update (right after model update) \"\"\"\n",
    "\n",
    "\n",
    "def update_ema(m):\n",
    "\twith torch.no_grad():\n",
    "\t\tfor name, param in m.named_parameters():\n",
    "\t\t\tif param.requires_grad:\n",
    "\t\t\t\tema_name = f\"ema_{name.replace('.', '_')}\"\n",
    "\t\t\t\tema_param = getattr(m, ema_name)\n",
    "\t\t\t\tema_param.mul_(model.ema_decay).add_(param.data, alpha=1 - model.ema_decay)\n",
    "\n",
    "\n",
    "\"\"\" Define EMA_params application (before validation) \"\"\"\n",
    "\n",
    "\n",
    "def apply_ema(m):\n",
    "\torg_params = {}\n",
    "\twith torch.no_grad():\n",
    "\t\tfor name, param in m.named_parameters():\n",
    "\t\t\tif param.requires_grad:\n",
    "\t\t\t\torg_param_name = f\"original_{name.replace('.', '_')}\"\n",
    "\t\t\t\torg_params[org_param_name] = param.data.clone()\n",
    "\t\t\t\tema_name = f\"ema_{name.replace('.', '_')}\"\n",
    "\t\t\t\tema_param = getattr(m, ema_name)\n",
    "\t\t\t\tparam.data.copy_(ema_param)\n",
    "\treturn org_params\n",
    "\n",
    "\n",
    "\"\"\" Define params_restoration \"\"\"\n",
    "\n",
    "\n",
    "def restore_org_params(m, org_params):\n",
    "\twith torch.no_grad():\n",
    "\t\tfor name, param in m.named_parameters():\n",
    "\t\t\tif param.requires_grad:\n",
    "\t\t\t\torg_param_name = f\"original_{name.replace('.', '_')}\"\n",
    "\t\t\t\tif org_param_name in org_params:\n",
    "\t\t\t\t\tparam.data.copy_(org_params[org_param_name])\n",
    "\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2024-02-16T12:27:18.975174Z",
     "end_time": "2024-02-16T12:27:18.975174Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "outputs": [],
   "source": [
    "\"\"\" Diffusion using X0 to get Xt \"\"\"\n",
    "\n",
    "\n",
    "def diffuse(X0, beta, t, device, noise=None):\n",
    "\t\"\"\"\n",
    "\tDiffusion Process from X0 to Xt\n",
    "\t:param X0: ground-truth image\n",
    "\t:param beta: scheduled variance, larger t larger beta\n",
    "\t:param t: time vector\n",
    "\t:param noise: noise input\n",
    "\t:param device: device\n",
    "\t:return: Xt, noisy img. at t\n",
    "\t\"\"\"\n",
    "\t# get mean & var --- q(Xt|X0) = N(Xt; sqrt(alpha_bar_t) * X0, 1-alpha_bar_t)\n",
    "\talpha_bar_t = my_utils.get_alpha_bar_t(beta, t).to(device)\n",
    "\tmean = torch.sqrt(alpha_bar_t) * X0\n",
    "\tvar = 1 - alpha_bar_t\n",
    "\t# diffuse to Xt\n",
    "\tif noise is None: noise = torch.randn_like(X0).to(device)\n",
    "\tXt = mean + torch.sqrt(var) * noise\n",
    "\treturn Xt"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2024-02-16T12:27:18.975174Z",
     "end_time": "2024-02-16T12:27:18.975174Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "outputs": [],
   "source": [
    "def train_DDPM(predictor: Unet, batch, loss_func, optimizer, device, verbose=False):\n",
    "\t\"\"\"\n",
    "\tTraining process: diffuse -> predict noise with Unet -> get loss\n",
    "\t:param predictor: Unet model for noise predicting\n",
    "\t:param batch: each element is a ground-truth img.\n",
    "\t:param loss_func: loss function (MSE)\n",
    "\t:param optimizer: Adam with default settings\n",
    "\t:param device: device\n",
    "\t:param verbose: whether to print messages in the process\n",
    "\t:return: noise_loss, the loss between pred_noise & ground-truth diffusion noise\n",
    "\t\"\"\"\n",
    "\t# prepare inputs\n",
    "\tbatch = batch.to(device)\n",
    "\tbatch_size = batch.shape[0]\n",
    "\tt = my_utils.get_t(batch_size, hp['train_T']).to(device)\n",
    "\tbeta = my_utils.variance_schedule(hp['train_T']).to(device)\n",
    "\tnoise = torch.randn_like(batch).to(device)\n",
    "\t# diffusion\n",
    "\tXt = diffuse(batch, beta, t, device, noise)\n",
    "\t# predict noise\n",
    "\toptimizer.zero_grad()\n",
    "\twith autocast():\n",
    "\t\tpredictor.zero_grad()\n",
    "\t\tpred_noise = predictor(Xt, t)\n",
    "\t\tif verbose: print(\"Predicting diffusion noise done.\")\n",
    "\t\t# get loss\n",
    "\t\tnoise_loss = loss_func(pred_noise, noise)\n",
    "\t\tif verbose: print(\"Got loss of diffusion noise: \", str(noise_loss.data.item()))\n",
    "\t\tscaler.scale(noise_loss).backward()\n",
    "\t\tscaler.step(optimizer)\n",
    "\t\tscaler.update()\n",
    "\t\tupdate_ema(predictor)\n",
    "\t\toptimizer.zero_grad()\n",
    "\treturn noise_loss.data.item()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2024-02-16T12:27:19.073681Z",
     "end_time": "2024-02-16T12:27:19.074681Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "outputs": [],
   "source": [
    "\"\"\" Sampling using trained model (sample after each epoch) \"\"\"\n",
    "\n",
    "\n",
    "def denoise(Xt, beta, t, device):\n",
    "\t\"\"\"\n",
    "\tDenoise process from Xt to X{t-1}\n",
    "\t:param Xt: noisy img. at t\n",
    "\t:param beta: scheduled variance, larger t larger beta\n",
    "\t:param t: time vector\n",
    "\t:return: X{t-1}, one-step denoised Xt\n",
    "\t:param device: device\n",
    "\t\"\"\"\n",
    "\t# predict noise_t\n",
    "\tpred_noise = model.forward(Xt, t)\n",
    "\t# get mean & var --- P(X{t-1}|Xt) = N(X{t-1}; mu(Xt, t, pred_noise), beta_t)\n",
    "\talpha_t = my_utils.get_alpha_t(beta, t).to(device)\n",
    "\talpha_bar_t = my_utils.get_alpha_bar_t(beta, t)\n",
    "\tmean = (Xt - ((1 - alpha_t) * pred_noise) / torch.sqrt(1 - alpha_bar_t)) / torch.sqrt(alpha_t)\n",
    "\tvar = 1 - alpha_t\n",
    "\t# denoise to X{t-1}\n",
    "\tnoise = torch.randn(Xt.shape, device=device)\n",
    "\tXt = mean + torch.sqrt(var) * noise\n",
    "\treturn Xt"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2024-02-16T12:27:19.074681Z",
     "end_time": "2024-02-16T12:27:19.074681Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "outputs": [],
   "source": [
    "# \"\"\" Test training \"\"\"\n",
    "#\n",
    "# batch = next(iter(train_batches))[0]\n",
    "# train_DDPM(model, batch, nn.MSELoss(), optim.Adam(model.parameters(), lr=hp['init_lr']), device, True)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2024-02-16T12:27:19.074681Z",
     "end_time": "2024-02-16T12:27:19.074681Z"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Complete Training Process"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch  1 / 5 batch  1  => loss:  5.582942008972168\n",
      "epoch  1 / 5 batch  2  => loss:  5.116004943847656\n",
      "epoch  1 / 5 batch  3  => loss:  5.265190601348877\n",
      "epoch  1 / 5 batch  4  => loss:  12.52369213104248\n",
      "epoch  1 / 5 batch  5  => loss:  12.988096237182617\n",
      "epoch  1 / 5 batch  6  => loss:  11.952946662902832\n",
      "epoch  1 / 5 batch  7  => loss:  2.888239622116089\n",
      "epoch  1 / 5 batch  8  => loss:  3.8575494289398193\n",
      "epoch  1 / 5 batch  9  => loss:  5.579803943634033\n",
      "epoch  1 / 5 batch  10  => loss:  3.357998847961426\n",
      "epoch  1 / 5 batch  11  => loss:  1.8653757572174072\n",
      "epoch  1 / 5 batch  12  => loss:  1.9750592708587646\n",
      "epoch  1 / 5 batch  13  => loss:  2.577693223953247\n",
      "epoch  1 / 5 batch  14  => loss:  2.633185386657715\n",
      "epoch  1 / 5 batch  15  => loss:  1.7281818389892578\n",
      "epoch  1 / 5 batch  16  => loss:  1.324298620223999\n",
      "epoch  1 / 5 batch  17  => loss:  1.3422884941101074\n",
      "epoch  1 / 5 batch  18  => loss:  1.6638582944869995\n",
      "epoch  1 / 5 batch  19  => loss:  1.7180092334747314\n",
      "epoch  1 / 5 batch  20  => loss:  1.6601461172103882\n",
      "epoch  1 / 5 batch  21  => loss:  1.2685260772705078\n",
      "epoch  1 / 5 batch  22  => loss:  1.1650116443634033\n",
      "epoch  1 / 5 batch  23  => loss:  1.143149733543396\n",
      "epoch  1 / 5 batch  24  => loss:  1.259211778640747\n",
      "epoch  1 / 5 batch  25  => loss:  1.107157826423645\n",
      "epoch  1 / 5 batch  26  => loss:  0.9846243262290955\n",
      "epoch  1 / 5 batch  27  => loss:  0.9551950097084045\n",
      "epoch  1 / 5 batch  28  => loss:  0.981773316860199\n",
      "epoch  1 / 5 batch  29  => loss:  0.9897991418838501\n",
      "epoch  1 / 5 batch  30  => loss:  0.9098743200302124\n",
      "epoch  1 / 5 batch  31  => loss:  0.8270025253295898\n",
      "epoch  1 / 5 batch  32  => loss:  0.8199887275695801\n",
      "epoch  1 / 5 batch  33  => loss:  0.8450168371200562\n",
      "epoch  1 / 5 batch  34  => loss:  0.7687530517578125\n",
      "epoch  1 / 5 batch  35  => loss:  0.78449547290802\n",
      "epoch  1 / 5 batch  36  => loss:  0.7459702491760254\n",
      "epoch  1 / 5 batch  37  => loss:  0.7068257927894592\n",
      "epoch  1 / 5 batch  38  => loss:  0.716655969619751\n",
      "epoch  1 / 5 batch  39  => loss:  0.6848095059394836\n",
      "epoch  1 / 5 batch  40  => loss:  0.6631949543952942\n",
      "epoch  1 / 5 batch  41  => loss:  nan\n",
      "epoch  1 / 5 batch  42  => loss:  nan\n",
      "epoch  1 / 5 batch  43  => loss:  nan\n",
      "epoch  1 / 5 batch  44  => loss:  nan\n",
      "epoch  1 / 5 batch  45  => loss:  nan\n",
      "epoch  1 / 5 batch  46  => loss:  nan\n",
      "epoch  1 / 5 batch  47  => loss:  nan\n",
      "epoch  1 / 5 batch  48  => loss:  nan\n",
      "epoch  1 / 5 batch  49  => loss:  nan\n",
      "epoch  1 / 5 batch  50  => loss:  nan\n",
      "epoch  1 / 5 batch  51  => loss:  nan\n",
      "epoch  1 / 5 batch  52  => loss:  nan\n",
      "epoch  1 / 5 batch  53  => loss:  nan\n",
      "epoch  1 / 5 batch  54  => loss:  nan\n",
      "epoch  1 / 5 batch  55  => loss:  nan\n",
      "epoch  1 / 5 batch  56  => loss:  nan\n",
      "epoch  1 / 5 batch  57  => loss:  nan\n",
      "epoch  1 / 5 batch  58  => loss:  nan\n",
      "epoch  1 / 5 batch  59  => loss:  nan\n",
      "epoch  1 / 5 batch  60  => loss:  nan\n",
      "epoch  1 / 5 batch  61  => loss:  nan\n",
      "epoch  1 / 5 batch  62  => loss:  nan\n",
      "epoch  1 / 5 batch  63  => loss:  nan\n",
      "epoch  1 / 5 batch  64  => loss:  nan\n",
      "epoch  1 / 5 batch  65  => loss:  nan\n",
      "epoch  1 / 5 batch  66  => loss:  nan\n",
      "epoch  1 / 5 batch  67  => loss:  nan\n",
      "epoch  1 / 5 batch  68  => loss:  nan\n",
      "epoch  1 / 5 batch  69  => loss:  nan\n",
      "epoch  1 / 5 batch  70  => loss:  nan\n",
      "epoch  1 / 5 batch  71  => loss:  nan\n",
      "epoch  1 / 5 batch  72  => loss:  nan\n",
      "epoch  1 / 5 batch  73  => loss:  nan\n",
      "epoch  1 / 5 batch  74  => loss:  nan\n",
      "epoch  1 / 5 batch  75  => loss:  nan\n",
      "epoch  1 / 5 batch  76  => loss:  nan\n",
      "epoch  1 / 5 batch  77  => loss:  nan\n",
      "epoch  1 / 5 batch  78  => loss:  nan\n",
      "epoch  1 / 5 batch  79  => loss:  nan\n",
      "epoch  1 / 5 batch  80  => loss:  nan\n",
      "epoch  1 / 5 batch  81  => loss:  nan\n",
      "epoch  1 / 5 batch  82  => loss:  nan\n",
      "epoch  1 / 5 batch  83  => loss:  nan\n",
      "epoch  1 / 5 batch  84  => loss:  nan\n",
      "epoch  1 / 5 batch  85  => loss:  nan\n",
      "epoch  1 / 5 batch  86  => loss:  nan\n",
      "epoch  1 / 5 batch  87  => loss:  nan\n",
      "epoch  1 / 5 batch  88  => loss:  nan\n",
      "epoch  1 / 5 batch  89  => loss:  nan\n",
      "epoch  1 / 5 batch  90  => loss:  nan\n",
      "epoch  1 / 5 batch  91  => loss:  nan\n",
      "epoch  1 / 5 batch  92  => loss:  nan\n",
      "epoch  1 / 5 batch  93  => loss:  nan\n",
      "epoch  1 / 5 batch  94  => loss:  nan\n",
      "epoch  1 / 5 batch  95  => loss:  nan\n",
      "epoch  1 / 5 batch  96  => loss:  nan\n",
      "epoch  1 / 5 batch  97  => loss:  nan\n",
      "epoch  1 / 5 batch  98  => loss:  nan\n",
      "epoch  1 / 5 batch  99  => loss:  nan\n",
      "epoch  1 / 5 batch  100  => loss:  nan\n",
      "epoch  1 / 5 batch  101  => loss:  nan\n",
      "epoch  1 / 5 batch  102  => loss:  nan\n",
      "epoch  1 / 5 batch  103  => loss:  nan\n",
      "epoch  1 / 5 batch  104  => loss:  nan\n",
      "epoch  1 / 5 batch  105  => loss:  nan\n",
      "epoch  1 / 5 batch  106  => loss:  nan\n",
      "epoch  1 / 5 batch  107  => loss:  nan\n",
      "epoch  1 / 5 batch  108  => loss:  nan\n",
      "epoch  1 / 5 batch  109  => loss:  nan\n",
      "epoch  1 / 5 batch  110  => loss:  nan\n",
      "epoch  1 / 5 batch  111  => loss:  nan\n",
      "epoch  1 / 5 batch  112  => loss:  nan\n",
      "epoch  1 / 5 batch  113  => loss:  nan\n",
      "epoch  1 / 5 batch  114  => loss:  nan\n",
      "epoch  1 / 5 batch  115  => loss:  nan\n",
      "epoch  1 / 5 batch  116  => loss:  nan\n",
      "epoch  1 / 5 batch  117  => loss:  nan\n",
      "epoch  1 / 5 batch  118  => loss:  nan\n",
      "epoch  1 / 5 batch  119  => loss:  nan\n",
      "epoch  1 / 5 batch  120  => loss:  nan\n",
      "epoch  1 / 5 batch  121  => loss:  nan\n",
      "epoch  1 / 5 batch  122  => loss:  nan\n",
      "epoch  1 / 5 batch  123  => loss:  nan\n",
      "epoch  1 / 5 batch  124  => loss:  nan\n",
      "epoch  1 / 5 batch  125  => loss:  nan\n",
      "epoch  1 / 5 batch  126  => loss:  nan\n",
      "epoch  1 / 5 batch  127  => loss:  nan\n",
      "epoch  1 / 5 batch  128  => loss:  nan\n",
      "epoch  1 / 5 batch  129  => loss:  nan\n",
      "epoch  1 / 5 batch  130  => loss:  nan\n",
      "epoch  1 / 5 batch  131  => loss:  nan\n",
      "epoch  1 / 5 batch  132  => loss:  nan\n",
      "epoch  1 / 5 batch  133  => loss:  nan\n",
      "epoch  1 / 5 batch  134  => loss:  nan\n",
      "epoch  1 / 5 batch  135  => loss:  nan\n",
      "epoch  1 / 5 batch  136  => loss:  nan\n",
      "epoch  1 / 5 batch  137  => loss:  nan\n",
      "epoch  1 / 5 batch  138  => loss:  nan\n",
      "epoch  1 / 5 batch  139  => loss:  nan\n",
      "epoch  1 / 5 batch  140  => loss:  nan\n",
      "epoch  1 / 5 batch  141  => loss:  nan\n",
      "epoch  1 / 5 batch  142  => loss:  nan\n",
      "epoch  1 / 5 batch  143  => loss:  nan\n",
      "epoch  1 / 5 batch  144  => loss:  nan\n",
      "epoch  1 / 5 batch  145  => loss:  nan\n",
      "epoch  1 / 5 batch  146  => loss:  nan\n",
      "epoch  1 / 5 batch  147  => loss:  nan\n",
      "epoch  1 / 5 batch  148  => loss:  nan\n",
      "epoch  1 / 5 batch  149  => loss:  nan\n",
      "epoch  1 / 5 batch  150  => loss:  nan\n",
      "epoch  1 / 5 batch  151  => loss:  nan\n",
      "epoch  1 / 5 batch  152  => loss:  nan\n",
      "epoch  1 / 5 batch  153  => loss:  nan\n",
      "epoch  1 / 5 batch  154  => loss:  nan\n",
      "epoch  1 / 5 batch  155  => loss:  nan\n",
      "epoch  1 / 5 batch  156  => loss:  nan\n",
      "epoch  1 / 5 batch  157  => loss:  nan\n",
      "epoch  1 / 5 batch  158  => loss:  nan\n",
      "epoch  1 / 5 batch  159  => loss:  nan\n",
      "epoch  1 / 5 batch  160  => loss:  nan\n",
      "epoch  1 / 5 batch  161  => loss:  nan\n",
      "epoch  1 / 5 batch  162  => loss:  nan\n",
      "epoch  1 / 5 batch  163  => loss:  nan\n",
      "epoch  1 / 5 batch  164  => loss:  nan\n",
      "epoch  1 / 5 batch  165  => loss:  nan\n",
      "epoch  1 / 5 batch  166  => loss:  nan\n",
      "epoch  1 / 5 batch  167  => loss:  nan\n",
      "epoch  1 / 5 batch  168  => loss:  nan\n",
      "epoch  1 / 5 batch  169  => loss:  nan\n",
      "epoch  1 / 5 batch  170  => loss:  nan\n",
      "epoch  1 / 5 batch  171  => loss:  nan\n",
      "epoch  1 / 5 batch  172  => loss:  nan\n",
      "epoch  1 / 5 batch  173  => loss:  nan\n",
      "epoch  1 / 5 batch  174  => loss:  nan\n",
      "epoch  1 / 5 batch  175  => loss:  nan\n",
      "epoch  1 / 5 batch  176  => loss:  nan\n",
      "epoch  1 / 5 batch  177  => loss:  nan\n",
      "epoch  1 / 5 batch  178  => loss:  nan\n",
      "epoch  1 / 5 batch  179  => loss:  nan\n",
      "epoch  1 / 5 batch  180  => loss:  nan\n",
      "epoch  1 / 5 batch  181  => loss:  nan\n",
      "epoch  1 / 5 batch  182  => loss:  nan\n",
      "epoch  1 / 5 batch  183  => loss:  nan\n",
      "epoch  1 / 5 batch  184  => loss:  nan\n",
      "epoch  1 / 5 batch  185  => loss:  nan\n",
      "epoch  1 / 5 batch  186  => loss:  nan\n",
      "epoch  1 / 5 batch  187  => loss:  nan\n",
      "epoch  1 / 5 batch  188  => loss:  nan\n",
      "epoch  1 / 5 batch  189  => loss:  nan\n",
      "epoch  1 / 5 batch  190  => loss:  nan\n",
      "epoch  1 / 5 batch  191  => loss:  nan\n",
      "epoch  1 / 5 batch  192  => loss:  nan\n",
      "epoch  1 / 5 batch  193  => loss:  nan\n",
      "epoch  1 / 5 batch  194  => loss:  nan\n",
      "epoch  1 / 5 batch  195  => loss:  nan\n",
      "epoch  1 / 5 batch  196  => loss:  nan\n",
      "epoch  1 / 5 batch  197  => loss:  nan\n",
      "epoch  1 / 5 batch  198  => loss:  nan\n",
      "epoch  1 / 5 batch  199  => loss:  nan\n",
      "epoch  1 / 5 batch  200  => loss:  nan\n",
      "epoch  1 / 5 batch  201  => loss:  nan\n",
      "epoch  1 / 5 batch  202  => loss:  nan\n",
      "epoch  1 / 5 batch  203  => loss:  nan\n",
      "epoch  1 / 5 batch  204  => loss:  nan\n",
      "epoch  1 / 5 batch  205  => loss:  nan\n",
      "epoch  1 / 5 batch  206  => loss:  nan\n",
      "epoch  1 / 5 batch  207  => loss:  nan\n",
      "epoch  1 / 5 batch  208  => loss:  nan\n",
      "epoch  1 / 5 batch  209  => loss:  nan\n",
      "epoch  1 / 5 batch  210  => loss:  nan\n",
      "epoch  1 / 5 batch  211  => loss:  nan\n",
      "epoch  1 / 5 batch  212  => loss:  nan\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mKeyboardInterrupt\u001B[0m                         Traceback (most recent call last)",
      "Cell \u001B[0;32mIn[14], line 27\u001B[0m\n\u001B[1;32m     25\u001B[0m \u001B[38;5;28;01mfor\u001B[39;00m batch \u001B[38;5;129;01min\u001B[39;00m train_batches:  \u001B[38;5;66;03m# iter. batches\u001B[39;00m\n\u001B[1;32m     26\u001B[0m \tb \u001B[38;5;241m+\u001B[39m\u001B[38;5;241m=\u001B[39m \u001B[38;5;241m1\u001B[39m\n\u001B[0;32m---> 27\u001B[0m \tloss \u001B[38;5;241m=\u001B[39m \u001B[43mtrain_DDPM\u001B[49m\u001B[43m(\u001B[49m\u001B[43mmodel\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mbatch\u001B[49m\u001B[43m[\u001B[49m\u001B[38;5;241;43m0\u001B[39;49m\u001B[43m]\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mloss_func\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43moptimizer\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mdevice\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m     28\u001B[0m \tb_loss\u001B[38;5;241m.\u001B[39mappend(loss)\n\u001B[1;32m     29\u001B[0m \ttol_loss \u001B[38;5;241m+\u001B[39m\u001B[38;5;241m=\u001B[39m loss\n",
      "Cell \u001B[0;32mIn[11], line 29\u001B[0m, in \u001B[0;36mtrain_DDPM\u001B[0;34m(predictor, batch, loss_func, optimizer, device, verbose)\u001B[0m\n\u001B[1;32m     27\u001B[0m noise_loss \u001B[38;5;241m=\u001B[39m loss_func(pred_noise, noise)\n\u001B[1;32m     28\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m verbose: \u001B[38;5;28mprint\u001B[39m(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mGot loss of diffusion noise: \u001B[39m\u001B[38;5;124m\"\u001B[39m, \u001B[38;5;28mstr\u001B[39m(noise_loss\u001B[38;5;241m.\u001B[39mdata\u001B[38;5;241m.\u001B[39mitem()))\n\u001B[0;32m---> 29\u001B[0m \u001B[43mscaler\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mscale\u001B[49m\u001B[43m(\u001B[49m\u001B[43mnoise_loss\u001B[49m\u001B[43m)\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mbackward\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m     30\u001B[0m scaler\u001B[38;5;241m.\u001B[39mstep(optimizer)\n\u001B[1;32m     31\u001B[0m scaler\u001B[38;5;241m.\u001B[39mupdate()\n",
      "File \u001B[0;32m~/anaconda3/envs/ypq/lib/python3.8/site-packages/torch/_tensor.py:396\u001B[0m, in \u001B[0;36mTensor.backward\u001B[0;34m(self, gradient, retain_graph, create_graph, inputs)\u001B[0m\n\u001B[1;32m    387\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m has_torch_function_unary(\u001B[38;5;28mself\u001B[39m):\n\u001B[1;32m    388\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m handle_torch_function(\n\u001B[1;32m    389\u001B[0m         Tensor\u001B[38;5;241m.\u001B[39mbackward,\n\u001B[1;32m    390\u001B[0m         (\u001B[38;5;28mself\u001B[39m,),\n\u001B[0;32m   (...)\u001B[0m\n\u001B[1;32m    394\u001B[0m         create_graph\u001B[38;5;241m=\u001B[39mcreate_graph,\n\u001B[1;32m    395\u001B[0m         inputs\u001B[38;5;241m=\u001B[39minputs)\n\u001B[0;32m--> 396\u001B[0m \u001B[43mtorch\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mautograd\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mbackward\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mgradient\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mretain_graph\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mcreate_graph\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43minputs\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43minputs\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[0;32m~/anaconda3/envs/ypq/lib/python3.8/site-packages/torch/autograd/__init__.py:173\u001B[0m, in \u001B[0;36mbackward\u001B[0;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001B[0m\n\u001B[1;32m    168\u001B[0m     retain_graph \u001B[38;5;241m=\u001B[39m create_graph\n\u001B[1;32m    170\u001B[0m \u001B[38;5;66;03m# The reason we repeat same the comment below is that\u001B[39;00m\n\u001B[1;32m    171\u001B[0m \u001B[38;5;66;03m# some Python versions print out the first line of a multi-line function\u001B[39;00m\n\u001B[1;32m    172\u001B[0m \u001B[38;5;66;03m# calls in the traceback and some print out the last line\u001B[39;00m\n\u001B[0;32m--> 173\u001B[0m \u001B[43mVariable\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_execution_engine\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mrun_backward\u001B[49m\u001B[43m(\u001B[49m\u001B[43m  \u001B[49m\u001B[38;5;66;43;03m# Calls into the C++ engine to run the backward pass\u001B[39;49;00m\n\u001B[1;32m    174\u001B[0m \u001B[43m    \u001B[49m\u001B[43mtensors\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mgrad_tensors_\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mretain_graph\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mcreate_graph\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43minputs\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    175\u001B[0m \u001B[43m    \u001B[49m\u001B[43mallow_unreachable\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43;01mTrue\u001B[39;49;00m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43maccumulate_grad\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43;01mTrue\u001B[39;49;00m\u001B[43m)\u001B[49m\n",
      "\u001B[0;31mKeyboardInterrupt\u001B[0m: "
     ]
    }
   ],
   "source": [
    "model = Unet(\n",
    "\thp['input_size'],\n",
    "\thp['in_chan'],\n",
    "\thp['out_chan'],\n",
    "\thp['t_chan'],\n",
    "\thp['fst_filters'],\n",
    "\thp['lst_chan'],\n",
    "\thp['groups'],\n",
    "\thp['drop_rate']\n",
    ").to(device)\n",
    "\n",
    "loss_func = nn.MSELoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=hp['init_lr'])\n",
    "\n",
    "# set epoch_num\n",
    "e_num = hp['epoch_num']\n",
    "\n",
    "# train loop\n",
    "e_loss = []  # losses of each epoch\n",
    "min_loss = None  # save the minimum loss (after each epoch)\n",
    "for e in range(e_num):  # iter. epochs\n",
    "\t\"\"\" training \"\"\"\n",
    "\tmodel.train()\n",
    "\tb_loss, b, tol_loss = [], 0, 0  # b_loss: losses (average) of each batch\n",
    "\tfor batch in train_batches:  # iter. batches\n",
    "\t\tb += 1\n",
    "\t\tloss = train_DDPM(model, batch[0], loss_func, optimizer, device)\n",
    "\t\tb_loss.append(loss)\n",
    "\t\ttol_loss += loss\n",
    "\t\tprint(\"epoch \", e + 1, \"/\", e_num, \"batch \", b, \" => loss: \", loss)\n",
    "\tbatch_num = b\n",
    "\torg_params = apply_ema(model)  # save original params\n",
    "\n",
    "\t\"\"\" validation \"\"\"\n",
    "\tmodel.eval()\n",
    "\twith torch.no_grad():\n",
    "\t\tb = 0\n",
    "\t\tfor batch in val_batches:\n",
    "\t\t\tb += 1\n",
    "\t\t\tbatch = batch[0].to(device)\n",
    "\t\t\tt = my_utils.get_t(hp['batch_size']*2, hp['train_T']).to(device)\n",
    "\t\t\tbeta = my_utils.variance_schedule(hp['train_T']).to(device)\n",
    "\t\t\tnoise = torch.randn_like(batch).to(device)\n",
    "\t\t\tXt = diffuse(batch, beta, t, device, noise)\n",
    "\t\t\tpred_noise = model(batch, t)\n",
    "\t\t\tval_loss = loss_func(pred_noise, noise)\n",
    "\t\t\tif min_loss is None or val_loss < min_loss:\n",
    "\t\t\t\tmin_loss = val_loss\n",
    "\t\t\t\tmy_utils.save_model_chk_point(\n",
    "\t\t\t\t\tcheckpoints_dir,\n",
    "\t\t\t\t\te, model, min_loss,\n",
    "\t\t\t\t\toptimizer\n",
    "\t\t\t\t)\n",
    "\n",
    "\t\"\"\" sampling \"\"\"\n",
    "\tmodel.eval()\n",
    "\twith torch.no_grad():\n",
    "\t\tnoises = torch.randn([hp['samples_num'], hp['in_chan'], hp['input_size'], hp['input_size']], device=device)\n",
    "\t\tbeta = my_utils.variance_schedule(hp['sampling_T']).to(device)\n",
    "\t\tfor t in range(hp['sampling_T'] - 1, -1, -1):\n",
    "\t\t\tt = noises.new_full((hp['samples_num'],), t, dtype=torch.long)\n",
    "\t\t\tXt = denoise(noises, beta, t, device)\n",
    "\tmy_utils.save_gen_chk_point(Xt, results_dir, e)\n",
    "\tprint(\"epoch \", e + 1, \"/\", e_num, \" => avg. loss: \", tol_loss / batch_num, \" val loss: \", val_loss.data.item())\n",
    "\n",
    "\t\"\"\" restore org_params \"\"\"\n",
    "\trestore_org_params(model, org_params)\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "outputs": [],
   "source": [
    "gc.collect()\n",
    "torch.cuda.empty_cache()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2024-02-24T18:10:08.477465Z",
     "end_time": "2024-02-24T18:10:08.477970Z"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
